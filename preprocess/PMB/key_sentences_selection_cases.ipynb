{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T02:34:14.039202Z",
     "start_time": "2021-06-29T02:34:14.036672Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T02:32:19.307912Z",
     "start_time": "2021-06-29T02:32:17.027995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11934, 11934, 27505, 27505)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_static_embeddings = torch.load(\n",
    "    '../ROT/data/Weibo/FN_bert-base-chinese_embeddings_static.pt')\n",
    "fn_dynamic_embeddings = torch.load(\n",
    "    '../ROT/data/Weibo/FN_bert-base-chinese_embeddings_dynamic.pt')\n",
    "dn_static_embeddings = torch.load(\n",
    "    '../ROT/data/Weibo/DN_bert-base-chinese_embeddings_static.pt')\n",
    "dn_dynamic_embeddings = torch.load(\n",
    "    '../ROT/data/Weibo/DN_bert-base-chinese_embeddings_dynamic.pt')\n",
    "\n",
    "len(fn_static_embeddings), len(fn_dynamic_embeddings), len(dn_static_embeddings), len(dn_dynamic_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T02:32:20.442977Z",
     "start_time": "2021-06-29T02:32:19.309532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11934, 27505)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../../dataset/Weibo/raw/FN_11934_filtered.json', 'r') as f:\n",
    "    FN = json.load(f)\n",
    "\n",
    "with open('../../dataset/Weibo/raw/DN_27505_filtered.json', 'r') as f:\n",
    "    DN = json.load(f)\n",
    "\n",
    "fnOid2item = {fn['_id']: fn for fn in FN}\n",
    "dnOid2item = {dn['_id']: dn for dn in DN}\n",
    "\n",
    "fnIdx2item = {i: fn for i, fn in enumerate(FN)}\n",
    "dnIdx2item = {i: dn for i, dn in enumerate(DN)}\n",
    "\n",
    "fnOid2idx = {fn['_id']: i for i, fn in enumerate(FN)}\n",
    "dnOid2idx = {dn['_id']: i for i, dn in enumerate(DN)}\n",
    "\n",
    "len(FN), len(DN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T02:32:20.446804Z",
     "start_time": "2021-06-29T02:32:20.444339Z"
    }
   },
   "outputs": [],
   "source": [
    "def pytorch_euclidean_distance(a, b):\n",
    "    return torch.dist(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claim-sentence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T02:34:39.241895Z",
     "start_time": "2021-06-29T02:34:39.232192Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sim_scores(fn_emb, dn_emb):\n",
    "    score_dict = dict()\n",
    "\n",
    "    for qidx, fn in enumerate(tqdm(FN)):\n",
    "        dn_oids = fn['debunking_ids']\n",
    "\n",
    "        for did in dn_oids:\n",
    "            dn = dnOid2item[did]\n",
    "            didx = dnOid2idx[did]\n",
    "\n",
    "            query = fn_emb[qidx]\n",
    "            sentences = dn_emb[didx]\n",
    "\n",
    "            items = [pytorch_euclidean_distance(\n",
    "                query, sent) for sent in sentences]\n",
    "\n",
    "            # Scale\n",
    "            m, M = min(items), max(items)\n",
    "            items = [1 - (x - m) / (M - m + 1e-8) for x in items]\n",
    "\n",
    "            if qidx not in score_dict.keys():\n",
    "                score_dict[qidx] = {didx: items}\n",
    "            else:\n",
    "                score_dict[qidx][didx] = items\n",
    "                \n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T02:35:26.998057Z",
     "start_time": "2021-06-29T02:34:40.770275Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11934/11934 [00:46<00:00, 258.20it/s]\n"
     ]
    }
   ],
   "source": [
    "scores_dynamic = get_sim_scores(fn_dynamic_embeddings, dn_dynamic_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T02:36:13.994845Z",
     "start_time": "2021-06-29T02:35:26.999731Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11934/11934 [00:46<00:00, 253.97it/s]\n"
     ]
    }
   ],
   "source": [
    "scores_static = get_sim_scores(fn_static_embeddings, dn_static_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T02:36:13.999774Z",
     "start_time": "2021-06-29T02:36:13.996709Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_in_color(s, cint=31, end='\\n'):\n",
    "    print('\\x1b[{}m{}\\x1b[0m'.format(cint, s), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T02:38:16.449787Z",
     "start_time": "2021-06-29T02:38:16.432993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.),\n",
       " tensor(0.9864),\n",
       " tensor(0.9283),\n",
       " tensor(0.8933),\n",
       " tensor(0.8823),\n",
       " tensor(0.7885),\n",
       " tensor(0.7509),\n",
       " tensor(0.7465),\n",
       " tensor(0.7306),\n",
       " tensor(0.7234),\n",
       " tensor(0.7197),\n",
       " tensor(0.7056),\n",
       " tensor(0.6803),\n",
       " tensor(0.6667),\n",
       " tensor(0.6539),\n",
       " tensor(0.6325),\n",
       " tensor(0.6219),\n",
       " tensor(0.5724),\n",
       " tensor(0.5424),\n",
       " tensor(0.5198),\n",
       " tensor(0.4378),\n",
       " tensor(0.3717),\n",
       " tensor(0.3205),\n",
       " tensor(0.1436),\n",
       " tensor(0.)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores_dynamic[0][19], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Dynamic & Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T02:44:36.843644Z",
     "start_time": "2021-06-29T02:44:36.820032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fake News]\n",
      "新冠病毒来源于美国的证据来了。应该是美国那家军事实验室泄露@魔法部之声 求大神解释\n",
      "\n",
      "---------------------------------------------\n",
      "qidx = 11580, didx = 22830\n",
      "\n",
      "[Debunking News]\n",
      "[Sent-0][\u001b[31mDynamic: 0.839\u001b[0m, Static: 0.581]\t#每日疫情快报#【最新辟谣】1. 新型冠状病毒是实验室制造的生物武器？\n",
      "[Sent-1][\u001b[31mDynamic: 1.000\u001b[0m, \u001b[31mStatic: 1.000\u001b[0m]\t辟谣：2月19日，在世卫组织东地中海区域办事处新闻发布会上，世卫组织东地中海区域主任称，没有证据表明新型冠状病毒是实验室制造的，也没有证据表明新冠病毒是以生物武器的身份制造出来的，新冠病毒来自动物界。\n",
      "[Sent-2][Dynamic: 0.484, Static: 0.316]\t 2. 新冠肺炎预警人之一，艾芬医生去世？\n",
      "[Sent-3][\u001b[31mDynamic: 0.736\u001b[0m, \u001b[31mStatic: 0.787\u001b[0m]\t辟谣：2月20日13时许，武汉经济广播官方微博发布消息称，2月20日中午12点44分，仍在一线工作的武汉市中心医院急诊科主任艾芬，利用午饭间隙，向所有关心关注她的朋友表示感谢。\n",
      "[Sent-4][Dynamic: 0.000, Static: 0.000]\t 3. 网传江苏省学校3月2日陆续开学？\n",
      "[Sent-5][Dynamic: 0.685, Static: 0.611]\t辟谣：这条信息来源于前几天网上流传的江苏某地开会会议讨论稿上的信息。\n",
      "[Sent-6][Dynamic: 0.370, Static: 0.339]\t江苏省政府、省教育厅、市政府、市教育局等官方网站、微信公众号、微博等从未发布过类似信息。\n",
      "[Sent-7][Dynamic: 0.531, \u001b[31mStatic: 0.652\u001b[0m]\t江苏省教育厅只在2月6日发布过通知：根据疫情发展情况，省政府决定，全省各级各类学校(高校、中小学、中职学校、幼儿园、托育机构)2月底前不开学。\n",
      "[Sent-8][Dynamic: 0.282, Static: 0.509]\t 【紧急寻人】最新患者同乘信息公示：1月31日：出租车，豫AA507Q，金水区总医院-金水区杨金路办事处新庄家园1月16日：火车，G518，武汉-信阳 2月8日：出租车，豫A1L7V6，中原区国棉四厂家属院-郑州市中心医院1月21日：火车，G3212，03号车厢，不详-郑州1月18日：飞机，A942，迪拜-北京1月31日：火车，Z190，武汉-郑州1月10日：火车，K735，郑州-巩义1月23日：火车，Z54，08号车厢，武汉-郑州百度APP搜索【新冠肺炎】或URL，了解更多新冠肺炎情况。\n"
     ]
    }
   ],
   "source": [
    "TOP = 3\n",
    "\n",
    "qidx = random.randint(0, len(FN) - 1)\n",
    "fn = FN[qidx]\n",
    "\n",
    "print('[Fake News]\\n{}'.format(fn['content_all']))\n",
    "\n",
    "for did in fn['debunking_ids']:\n",
    "    didx = dnOid2idx[did]\n",
    "    dn = DN[didx]\n",
    "\n",
    "    s_dynamic = scores_dynamic[qidx][didx]\n",
    "    s_static = scores_static[qidx][didx]\n",
    "\n",
    "    top_s_dynamic = sorted(s_dynamic, reverse=True)[:TOP]\n",
    "    top_s_static = sorted(s_static, reverse=True)[:TOP]\n",
    "\n",
    "    print('\\n---------------------------------------------')\n",
    "    print('qidx = {}, didx = {}\\n'.format(qidx, didx))\n",
    "\n",
    "    print('[Debunking News]')\n",
    "    for j, sent in enumerate(dn['content_all']):\n",
    "        print('[Sent-{}]['.format(j), end='')\n",
    "\n",
    "        print_func = print_in_color if s_dynamic[j] in top_s_dynamic else print\n",
    "        print_func('Dynamic: {:.3f}'.format(s_dynamic[j]), end='')\n",
    "\n",
    "        print(', ', end='')\n",
    "\n",
    "        print_func = print_in_color if s_static[j] in top_s_static else print\n",
    "        print_func('Static: {:.3f}'.format(s_static[j]), end='')\n",
    "\n",
    "        print(']\\t{}'.format(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern-sentence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Sentence Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
